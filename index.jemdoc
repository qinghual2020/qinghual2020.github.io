# jemdoc: nofooter
==Qinghua Liu

~~~
{}{img_left}{photo-24 copy.JPG}{alt text}{240}{267}


I am a researcher at OpenAI. I work on post-training.



I received my Ph.D. from Princeton, advised by [https://sites.google.com/view/cjin/home Chi Jin]. 
My PhD research focused on fundamental theories in reinforcement learning (RL), including partially observable RL ([https://arxiv.org/abs/2204.08967 POMDP], 
[https://arxiv.org/abs/2209.14997 PSR], [PORL_Survey.pdf Survey]), multi-agent RL ([https://arxiv.org/abs/2110.14555 Stochastic Game]), 
 and   RL with large state spaces ([https://arxiv.org/abs/2102.00815 Function Approximation]).
 After that, I spent a wonderful year as a postdoctoral researcher at [https://www.microsoft.com/en-us/research/theme/machine-learning-ai-nyc/people/ Microsoft Research NYC], where I explored language model research.





During summer 2022, I interned at DeepMind, working with 
 [https://sites.ualberta.ca/~szepesva/ Csaba Szepesvári] and Gellért Weisz.
Previously, I received a  B.E. degree in Electrical Engineering and a B.S. degree in Mathematics from Tsinghua University.

#I will be joining WashU CS as an assistant professor in the fall of 2025.

 \[[https://scholar.google.com/citations?user=CotFJJsAAAAJ&hl=en Google Scholar]\]


 ~~~




== Selected Works ~~([pubs_list.html Show All])

*    *(α-β order) denotes alphabetical authorship ordering \n

\n 

-  [https://chatgpt.com/ GPT-5 Multi-Personality] \[[https://openai.com/index/introducing-gpt-5/ blog]\] \[[https://x.com/OpenAI/status/1953534071772262511 twitter]\]
\n
OpenAI\n
Most frontiers models can ace tough reasoning problems but still miss the subtleties of human emotion. This is our initial step toward AI that gets the feels, not just the correctness.

\n

- [https://arxiv.org/abs/2209.14997 Optimistic MLE -- A Generic Model-based Algorithm for Partially Observable Sequential Decision Making]\n
 *Qinghua Liu*, Praneeth Netrapalli, Csaba Szepesvári, Chi Jin\n
 Symposium on Theory of Computing (STOC), 2023

\n

- [https://arxiv.org/abs/2110.14555 V-Learning -- A Simple, Efficient, Decentralized Algorithm for Multiagent RL] \n
(α-β order) Chi Jin, *Qinghua Liu*, Yuanhao Wang, Tiancheng Yu \n
 Mathematics of Operations Research (MOR), 2023 \n
 \ *Best Paper*  in ICLR 2022 ``Gamification and Multiagent Solutions'' Workshop \n  
 #\ *{{<font color=AB3D58>Best Paper</font>}}*  in ICLR  Workshop on Gamification and Multiagent Solutions, 2022 \n  

\n

- [https://arxiv.org/abs/2204.08967 When Is Partially Observable Reinforcement Learning Not Scary?] \n
 *Qinghua Liu*, Alan Chung, Csaba Szepesvári, Chi Jin\n
Conference on Learning Theory (COLT), 2022


\n

- [https://arxiv.org/abs/2102.00815 Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms] \n
(α-β order)  Chi Jin, *Qinghua Liu*, Sobhan Miryoosefi \n
Neural Information Processing Systems (NeurIPS), 2021 (*Spotlight*) 
#Neural Information Processing Systems (NeurIPS), 2021 (*{{<font color=AB3D58>Spotlight</font>}}*) 

\n

\n




