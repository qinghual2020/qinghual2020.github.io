<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Qinghua Liu</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Qinghua Liu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Qinghua Liu</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photo.jpeg" alt="alt text" width="200px" height="246px" />&nbsp;</td>
<td align="left"><p><br /> <br />
I am a Ph.D. candidate in the Department of Electrical and Computer Engineering at Princeton University. I am fortunate to be advised by <a href="https://sites.google.com/view/cjin/home">Chi Jin</a>. <br /></p>
<p>My current research interests focus on reinforcement learning theory.
I am particularly interested in RL problems related to <a href="https://arxiv.org/abs/2102.00815">function approximation</a>, <a href="https://arxiv.org/abs/2204.08967">partial observability</a> and <a href="https://arxiv.org/abs/2110.14555">game theory</a>.<br /></p>
<p>During summer 2022, I was a research scientist intern at DeepMind, London, working with 
<a href="https://sites.ualberta.ca/~szepesva/">Csaba Szepesvári</a> and <a href="https://scholar.google.com/citations?user=NBl5GvcAAAAJ&amp;hl=en">Gellért Weisz</a></p>
<p>Previously, I received a  B.E. degree in Electrical Engineering and a B.S. degree in Mathematics from Tsinghua University in 2018.</p>
</td></tr></table>
<h2>Recent Papers</h2>
<p><b>    </b>(α-β order) denotes alphabetical authorship ordering, and (*) denotes equal contribution <br />
<br /></p>
<ul>
<li><p><a href="omle.pdf">Optimistic MLE—A Generic Model-based Algorithm for Partially Observable Sequential Decision Making</a><br />
<b>Qinghua Liu</b>, Praneeth Netrapalli, Csaba Szepesvári, Chi Jin<br />
arXiv preprint</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2206.01315">Sample-Efficient Reinforcement Learning of Partially Observable Markov Games</a> <br />
<b>Qinghua Liu</b>, Csaba Szepesvári, Chi Jin<br />
Neural Information Processing Systems (NeurIPS), 2022 <br />
European Workshop on Reinforcement Learning, 2022 (<font color=AB3D58>Oral presentation</font>) </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2206.02640">Policy Optimization for Markov Games: Unified Framework and Faster Convergence</a> <br />
Runyu Zhang*, <b>Qinghua Liu*</b>, Huan Wang, Caiming Xiong, Na Li, Yu Bai<br />
Neural Information Processing Systems (NeurIPS), 2022</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2204.08967">When Is Partially Observable Reinforcement Learning Not Scary?</a> <br />
<b>Qinghua Liu</b>, Alan Chung, Csaba Szepesvári, Chi Jin<br />
Conference on Learning Theory (COLT), 2022</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2203.06803">Learning Markov Games with Adversarial Opponents: Efficient Algorithms and Fundamental Limits</a> <br />
<b>Qinghua Liu*</b>, Yuanhao Wang*, Chi Jin <br />
International Conference on Machine Learning (ICML), 2022 (<font color=AB3D58>Long presentation</font>)</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2207.08894">A Deep Reinforcement Learning Approach for Finding Non-Exploitable Strategies in Two-Player Atari Games</a> <br />
Zihan Ding, Dijia Su, <b>Qinghua Liu</b>, Chi Jin<br />
arXiv preprint</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2110.14555">V-Learning &ndash; A Simple, Efficient, Decentralized Algorithm for Multiagent RL</a> <br />
(α-β order) Chi Jin, <b>Qinghua Liu</b>, Yuanhao Wang, Tiancheng Yu <br />
arXiv preprint; <font color=AB3D58>Best Paper</font>  in ICLR  Workshop on Gamification and Multiagent Solutions, 2022 <br /> </p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2106.03352">The Power of Exploiter: Provable Multi-Agent RL in Large State Spaces</a> <br />
(α-β order)  Chi Jin, <b>Qinghua Liu</b>, Tiancheng Yu <br />
International Conference on Machine Learning (ICML), 2022 <br />
ICML Workshop on Reinforcement Learning Theory, 2021 <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2102.00815">Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms</a> [<a href="bedim_slides.pdf"><font color=2E86C1>Slides</font></a>] [<a href="https://www.youtube.com/watch?v=-iz26FSdaKM"><font color=AE8062>RL Theory Seminar</font></a>] <br />
(α-β order)  Chi Jin, <b>Qinghua Liu</b>, Sobhan Miryoosefi <br />
Neural Information Processing Systems (NeurIPS), 2021 (<font color=AB3D58>Spotlight</font>)</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2010.01604">A Sharp Analysis of Model-based Reinforcement Learning with Self-Play</a> <br />
<b>Qinghua Liu</b>, Tiancheng Yu, Yu Bai, Chi Jin<br />
International Conference on Machine Learning (ICML), 2021</p>
</li>
</ul>
<ul>
<li><p><a href="https://openreview.net/pdf?id=hx1IXFHAw7R">Provable Rich Observation Reinforcement Learning with Combinatorial Latent States</a><br />
Dipendra Misra, <b>Qinghua Liu</b>, Chi Jin, John Langford<br />
International Conference on Learning Representations (ICLR), 2021</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2006.12484">Sample-Efficient Reinforcement Learning of Undercomplete POMDPs</a> [<a href="pomdps_slides.pdf"><font color=2E86C1>Slides</font></a>]
[<a href="https://www.youtube.com/watch?v=lGI1MrSXHfs&amp;t=9s&amp;ab_channel=RLtheoryseminars"><font color=AE8062>RL Theory Seminar</font></a>] <br />
(α-β order)  Chi Jin, Sham M. Kakade, Akshay Krishnamurthy, <b>Qinghua Liu</b> <br />
Neural Information Processing Systems (NeurIPS), 2020 (<font color=AB3D58>Spotlight</font>)</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2007.07481">Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization</a><br />
Jianyu Wang, <b>Qinghua Liu</b>, Hao Liang, Gauri Joshi, H. Vincent Poor<br />
Neural Information Processing Systems (NeurIPS), 2020<br /> 
Longer version in IEEE Transactions on Signal Processing</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2012.13326">A Tight Lower Bound for Uniformly Stable Algorithms</a><br />
(α-β order)  <b>Qinghua Liu</b>, Zhou Lu <br />
arXiv preprint</p>
</li>
</ul>
<h2>Services </h2>
<p>Reviewers for COLT, NeurIPS, ICML, JMLR, ICLR, ALT, IEEE-TSP, IEEE-TAC, etc.</p>
<p><br /></p>
</td>
</tr>
</table>
</body>
</html>
